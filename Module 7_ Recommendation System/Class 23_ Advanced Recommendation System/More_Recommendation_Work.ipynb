{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a User-User Recommendation Engine"
      ],
      "metadata": {
        "id": "N5MPZGr93flL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cuoRl15k3Oqg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_movielens(url, path='movielens.zip'):\n",
        "    response = requests.get(url)\n",
        "    with open(path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"movielens\")\n",
        "\n",
        "dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "download_movielens(dataset_url)\n",
        "\n",
        "# Load the dataset\n",
        "ratings = pd.read_csv('movielens/ml-latest-small/ratings.csv', usecols=['userId', 'movieId', 'rating'])\n"
      ],
      "metadata": {
        "id": "nevEjXC-3RmO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a user-item matrix\n",
        "user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Convert the user-item matrix into a sparse matrix\n",
        "sparse_user_item = csr_matrix(user_item_matrix)\n",
        "\n",
        "# Compute cosine similarity between users\n",
        "user_similarity = cosine_similarity(sparse_user_item)"
      ],
      "metadata": {
        "id": "ZIQBrl7W3WC1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation function\n",
        "def recommend_movies(user_id, num_recommendations=5):\n",
        "    similarity_scores = user_similarity[user_id - 1]\n",
        "    sorted_indices = np.argsort(similarity_scores)[::-1]\n",
        "    top_users = sorted_indices[1:num_recommendations+1]  # skip the first user as it will be the target user itself\n",
        "\n",
        "    recommended_movies = set()\n",
        "    for similar_user in top_users:\n",
        "        similar_user_movies = user_item_matrix.columns[np.argsort(user_item_matrix.iloc[similar_user])][::-1]\n",
        "        recommended_movies.update(similar_user_movies[:num_recommendations])\n",
        "\n",
        "    return list(recommended_movies)[:num_recommendations]\n",
        "\n"
      ],
      "metadata": {
        "id": "6Agn7FNY2v6c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "user_id = 1\n",
        "recommendations = recommend_movies(user_id)\n",
        "print(f\"Recommended Movies for User {user_id}:\", recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-t3Ide43dd7",
        "outputId": "e9bc9864-1a31-4690-a7e2-af7f67ba7998"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Movies for User 1: [1, 899, 904, 3081, 2959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doing the same thing but using Matrix Factorization"
      ],
      "metadata": {
        "id": "qCs9wdcF3jOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "L2lFJRkh3mnE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_movielens(url, path='movielens.zip'):\n",
        "    response = requests.get(url)\n",
        "    with open(path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"movielens\")\n",
        "\n",
        "dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "download_movielens(dataset_url)\n",
        "\n",
        "ratings = pd.read_csv('movielens/ml-latest-small/ratings.csv', usecols=['userId', 'movieId', 'rating'])\n"
      ],
      "metadata": {
        "id": "UO-uO89t3q9A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Normalize the matrix\n",
        "user_ratings_mean = np.mean(user_item_matrix, axis=1)\n",
        "user_item_matrix_demeaned = user_item_matrix.sub(user_ratings_mean, axis=0)\n",
        "\n",
        "# Convert to a numpy array\n",
        "user_item_matrix_demeaned_np = user_item_matrix_demeaned.values"
      ],
      "metadata": {
        "id": "PR5u-tsM3zT2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform SVD, k is the number of factors\n",
        "U, sigma, Vt = svds(user_item_matrix_demeaned_np, k=50)\n",
        "\n",
        "# Convert sigma to a diagonal matrix\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Predict ratings\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.values.reshape(-1, 1)\n",
        "\n",
        "# Convert predicted ratings to DataFrame\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_item_matrix.columns)\n"
      ],
      "metadata": {
        "id": "EChDpBQ137IO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_items(user_id, num_recommendations=5):\n",
        "    user_row_number = user_id - 1\n",
        "    sorted_user_ratings = predicted_ratings_df.iloc[user_row_number].sort_values(ascending=False)\n",
        "\n",
        "    # Get the user's data and merge in the movie information\n",
        "    user_data = ratings[ratings.userId == user_id]\n",
        "    sorted_user_predictions = sorted_user_ratings.drop(user_data.movieId.tolist()).head(num_recommendations)\n",
        "    recommendations = pd.DataFrame({'movieId': sorted_user_predictions.index, 'predictedRating': sorted_user_predictions.values})\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "OsVQTzS94Hn8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "user_id = 1\n",
        "recommendations = recommend_items(user_id)\n",
        "print(\"Recommended Movies for User ID\", user_id)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw5oEObD4Lw9",
        "outputId": "503284ec-ef57-43e4-a774-91202e9efc1f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Movies for User ID 1\n",
            "   movieId  predictedRating\n",
            "0     1036         4.024307\n",
            "1     1221         3.324815\n",
            "2     1387         3.304728\n",
            "3      858         2.891690\n",
            "4     1968         2.870832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Surprise for training a model with Matrix Factorization"
      ],
      "metadata": {
        "id": "uRWYIlJY4f0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TRsgkOp40fs",
        "outputId": "2870729d-a9ad-4788-835e-8e03b632b48c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD, accuracy, BaselineOnly\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Use the SVD algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Train\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_after_training = accuracy.rmse(predictions)\n",
        "\n",
        "# Do the same for baseline\n",
        "baseline_algo = BaselineOnly()\n",
        "baseline_algo.fit(trainset)\n",
        "baseline_predictions = baseline_algo.test(testset)\n",
        "baseline_rmse = accuracy.rmse(baseline_predictions)\n",
        "\n",
        "print(f\"RMSE after Training: {rmse_after_training}\")\n",
        "print(f\"Baseline RMSE: {baseline_rmse}\")\n",
        "\n",
        "# Check if the model improved\n",
        "if rmse_after_training < baseline_rmse:\n",
        "    print(\"Training improved the model.\")\n",
        "else:\n",
        "    print(\"Training did not improve the model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHjSRv8i44eS",
        "outputId": "55603cc8-c16d-411c-9a92-9404ee37c155"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9518\n",
            "Estimating biases using als...\n",
            "RMSE: 0.9554\n",
            "RMSE after Training: 0.9518366013143656\n",
            "Baseline RMSE: 0.9553704400771427\n",
            "Training improved the model.\n"
          ]
        }
      ]
    }
  ]
}