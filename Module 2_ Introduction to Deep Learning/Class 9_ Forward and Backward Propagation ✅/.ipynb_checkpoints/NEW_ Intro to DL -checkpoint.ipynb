{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ajWMdsaF5Ou"
   },
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "PyTorch is an open-source machine learning library developed by Facebook's AI Research lab. It is widely used for deep learning and artificial intelligence applications, offering dynamic computation graphs, a variety of pre-built layers, and optimization algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Krkn4-yS0CYG"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoagGjuV0E9n"
   },
   "source": [
    "## Tensor Generation and Manipulation\n",
    "\n",
    "Tensors are the fundamental building blocks in PyTorch, similar to arrays in NumPy. They can store data of various types and are optimized for accelerated computing on GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8AmNog60GdF",
    "outputId": "9652e883-1762-464c-952b-3d251f5bda80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([1, 2, 3, 4])\n",
      "Matrix B: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Tensor C: tensor([2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# Creating a Tensor\n",
    "tensor_a = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Displaying the Tensor\n",
    "print(\"Tensor A:\", tensor_a)\n",
    "\n",
    "# Creating a Matrix\n",
    "matrix_b = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# Displaying the Matrix\n",
    "print(\"Matrix B:\", matrix_b)\n",
    "\n",
    "# Manipulating Tensors\n",
    "tensor_c = tensor_a * 2\n",
    "\n",
    "# Displaying the Result\n",
    "print(\"Tensor C:\", tensor_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSDcfSFr8zFb",
    "outputId": "25e3b7ff-4789-4164-ea6a-68664f68e473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = \n",
      " tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.]])\n",
      "a * b = \n",
      " tensor([[ 6., 10., 12.],\n",
      "        [12., 10.,  6.]])\n",
      "a @ b.T = \n",
      " tensor([[12.,  9.,  6.],\n",
      "        [30., 23., 16.],\n",
      "        [48., 37., 26.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of size 2x3\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# Create another tensor with the same size\n",
    "b = torch.tensor([[6, 5, 4], [3, 2, 1]], dtype=torch.float32)\n",
    "\n",
    "# Elementwise addition\n",
    "c = a + b\n",
    "\n",
    "# Elementwise multiplication\n",
    "d = a * b\n",
    "\n",
    "# Matrix multiplication (reshaping a to be 3x2)\n",
    "e = torch.mm(a.view(3, 2), b)\n",
    "\n",
    "print(\"a + b = \\n\", c)\n",
    "print(\"a * b = \\n\", d)\n",
    "\n",
    "# @ denotes matrix multiplication in PyTorch\n",
    "print(\"a @ b.T = \\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3hhpa9o0JTV"
   },
   "source": [
    "## Setting Up a Basic Linear Neural Network\n",
    "\n",
    "In this section, we will set up a basic linear neural network using PyTorch. This network will consist of an input layer, a hidden layer, and an output layer, each having linear units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cYPRhbE0Kwq",
    "outputId": "fbae845c-9d8d-4c18-d83c-cece9c18b0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNN(\n",
      "  (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the Neural Network\n",
    "class LinearNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinearNN, self).__init__()\n",
    "\n",
    "        # Input Layer to Hidden Layer\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Hidden Layer to Output Layer\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the Neural Network\n",
    "input_size = 3\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "model = LinearNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Display the Model Architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C41Kmb8n0N_1"
   },
   "source": [
    " PyTorch's simplicity and flexibility make it a popular choice for building deep learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVvuCvSm9KuC"
   },
   "source": [
    "# Walk-through of deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEacJyQ69TO8"
   },
   "source": [
    "## Basic Data Loader for Iris Dataset\n",
    "\n",
    "For loading the Iris dataset, we can use `sklearn` to load the dataset and `torch.utils.data` to create a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bwipMNu9PrY",
    "outputId": "7e14f1c9-548e-435a-fdf4-ad78fb064e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: tensor([[6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000]])\n",
      "Labels: tensor([1, 2, 0, 2])\n",
      "Features: tensor([[5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000]])\n",
      "Labels: tensor([0, 1, 1, 0])\n",
      "Features: tensor([[4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000]])\n",
      "Labels: tensor([0, 1, 0, 0])\n",
      "Features: tensor([[5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000]])\n",
      "Labels: tensor([1, 0, 1, 0])\n",
      "Features: tensor([[5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000]])\n",
      "Labels: tensor([0, 0, 0, 1])\n",
      "Features: tensor([[5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [4.9000, 3.6000, 1.4000, 0.1000]])\n",
      "Labels: tensor([1, 2, 2, 0])\n",
      "Features: tensor([[4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000]])\n",
      "Labels: tensor([0, 0, 2, 2])\n",
      "Features: tensor([[5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000]])\n",
      "Labels: tensor([0, 2, 2, 1])\n",
      "Features: tensor([[4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.2000]])\n",
      "Labels: tensor([1, 0, 2, 0])\n",
      "Features: tensor([[5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000]])\n",
      "Labels: tensor([1, 0, 1, 0])\n",
      "Features: tensor([[5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000]])\n",
      "Labels: tensor([2, 1, 2, 2])\n",
      "Features: tensor([[5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000]])\n",
      "Labels: tensor([1, 1, 1, 1])\n",
      "Features: tensor([[4.9000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000]])\n",
      "Labels: tensor([0, 0, 1, 2])\n",
      "Features: tensor([[6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000]])\n",
      "Labels: tensor([2, 2, 1, 2])\n",
      "Features: tensor([[6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000]])\n",
      "Labels: tensor([2, 2, 2, 0])\n",
      "Features: tensor([[6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000]])\n",
      "Labels: tensor([1, 2, 2, 0])\n",
      "Features: tensor([[5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000]])\n",
      "Labels: tensor([1, 0, 1, 1])\n",
      "Features: tensor([[7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000]])\n",
      "Labels: tensor([2, 2, 1, 0])\n",
      "Features: tensor([[4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000]])\n",
      "Labels: tensor([0, 0, 0, 2])\n",
      "Features: tensor([[4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000]])\n",
      "Labels: tensor([0, 1, 1, 1])\n",
      "Features: tensor([[5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000]])\n",
      "Labels: tensor([0, 0, 2, 0])\n",
      "Features: tensor([[5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000]])\n",
      "Labels: tensor([1, 0, 2, 2])\n",
      "Features: tensor([[7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000]])\n",
      "Labels: tensor([2, 0, 2, 0])\n",
      "Features: tensor([[5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000]])\n",
      "Labels: tensor([0, 2, 2, 1])\n",
      "Features: tensor([[5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000]])\n",
      "Labels: tensor([1, 0, 1, 1])\n",
      "Features: tensor([[6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000]])\n",
      "Labels: tensor([1, 0, 0, 2])\n",
      "Features: tensor([[5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000]])\n",
      "Labels: tensor([0, 1, 2, 0])\n",
      "Features: tensor([[6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000]])\n",
      "Labels: tensor([1, 1, 1, 0])\n",
      "Features: tensor([[7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000]])\n",
      "Labels: tensor([1, 2, 1, 1])\n",
      "Features: tensor([[4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000]])\n",
      "Labels: tensor([0, 2, 2, 2])\n",
      "Features: tensor([[4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000]])\n",
      "Labels: tensor([2, 2, 1, 2])\n",
      "Features: tensor([[6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000]])\n",
      "Labels: tensor([2, 0, 1, 0])\n",
      "Features: tensor([[6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000]])\n",
      "Labels: tensor([1, 2, 1, 1])\n",
      "Features: tensor([[5.9000, 3.0000, 5.1000, 1.8000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000]])\n",
      "Labels: tensor([2, 1, 2, 0])\n",
      "Features: tensor([[6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000]])\n",
      "Labels: tensor([2, 1, 2, 0])\n",
      "Features: tensor([[4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000]])\n",
      "Labels: tensor([0, 2, 1, 2])\n",
      "Features: tensor([[7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000]])\n",
      "Labels: tensor([2, 1, 0, 0])\n",
      "Features: tensor([[6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000]])\n",
      "Labels: tensor([2, 1])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for data, target in dataloader:\n",
    "    print(\"Features:\", data)\n",
    "    print(\"Labels:\", target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXCxJEg69rqG"
   },
   "source": [
    "## Building a Basic Neural Network with PyTorch\n",
    "\n",
    "Next, let's define a simple neural network with one hidden layer using PyTorch's `nn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9F_dB3b9rV3",
    "outputId": "9e789ed0-6caa-45b0-c0aa-fe4170b2c5c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)  # Input layer: 4 features from Iris dataset -> 10 neuron hidden layer\n",
    "        self.fc2 = nn.Linear(10, 3)  # Hidden layer to output layer (3 classes in Iris dataset)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # Activation function for hidden layer\n",
    "        x = self.fc2(x)          # softmax will be applied in the loss\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "net = SimpleNet()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goaFjoGt-Gy8"
   },
   "source": [
    "## Backpropagation Steps\n",
    "\n",
    "Now we'll demonstrate the training step with backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gQP4gIC-GmJ",
    "outputId": "a7e2e5f9-a6eb-4830-8181-912e1841b1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.007826566696167\n",
      "Loss: 0.9780124425888062\n",
      "Loss: 0.9891467690467834\n",
      "Loss: 1.0046708583831787\n",
      "Loss: 0.9767104387283325\n",
      "Loss: 0.952328622341156\n",
      "Loss: 0.954338550567627\n",
      "Loss: 1.0007487535476685\n",
      "Loss: 0.9462482929229736\n",
      "Loss: 0.982812762260437\n",
      "Loss: 0.9966928958892822\n",
      "Loss: 1.0285638570785522\n",
      "Loss: 0.9537361264228821\n",
      "Loss: 0.9312126636505127\n",
      "Loss: 0.8458393812179565\n",
      "Loss: 0.9640127420425415\n",
      "Loss: 1.0650484561920166\n",
      "Loss: 0.9855878949165344\n",
      "Loss: 0.8299514055252075\n",
      "Loss: 0.8857778906822205\n",
      "Loss: 0.9816800355911255\n",
      "Loss: 0.957220196723938\n",
      "Loss: 0.9471221566200256\n",
      "Loss: 0.9627971053123474\n",
      "Loss: 0.8822465538978577\n",
      "Loss: 0.9332735538482666\n",
      "Loss: 0.9742507338523865\n",
      "Loss: 0.8983879089355469\n",
      "Loss: 1.019282341003418\n",
      "Loss: 0.8620442748069763\n",
      "Loss: 0.8929808139801025\n",
      "Loss: 0.926068902015686\n",
      "Loss: 1.0127921104431152\n",
      "Loss: 0.9584394693374634\n",
      "Loss: 0.8840899467468262\n",
      "Loss: 0.8380993604660034\n",
      "Loss: 0.7658309936523438\n",
      "Loss: 0.9988470077514648\n"
     ]
    }
   ],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Training\n",
    "for data, target in dataloader:\n",
    "    # Zero the gradient buffers\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    output = net(data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backpropagation: Compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
